{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85fd37c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pathlib in /home/kwib/.local/lib/python3.9/site-packages (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4f57430",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pygments==2.13.0 in /home/kwib/.local/lib/python3.9/site-packages (2.13.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pygments==2.13.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9203a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numpy==1.23 in /home/kwib/.local/lib/python3.9/site-packages (1.23.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy==1.23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b463a7d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pytorch_tabular in /home/kwib/.local/lib/python3.9/site-packages (1.0.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (2.0.0)\n",
      "Requirement already satisfied: pytorch-lightning==1.8.* in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (1.8.6)\n",
      "Requirement already satisfied: ipywidgets in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch_tabular) (7.6.5)\n",
      "Requirement already satisfied: torchmetrics==0.11.* in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (0.11.4)\n",
      "Requirement already satisfied: PyYAML<=5.4.1,>=5.1 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (5.4.1)\n",
      "Requirement already satisfied: category-encoders==2.5.* in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (2.5.1.post0)\n",
      "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (2.11.0)\n",
      "Requirement already satisfied: matplotlib>3.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch_tabular) (3.4.3)\n",
      "Requirement already satisfied: rich>=10.2.2 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (13.3.5)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.17.2 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (1.23.0)\n",
      "Requirement already satisfied: omegaconf>=2.0.1 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (2.3.0)\n",
      "Requirement already satisfied: einops==0.6.* in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (0.6.0)\n",
      "Requirement already satisfied: protobuf<=3.20.* in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (3.19.6)\n",
      "Requirement already satisfied: pytorch-tabnet==4.0 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (4.0)\n",
      "Requirement already satisfied: torch>=1.8.1 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch_tabular) (1.13.1)\n",
      "Requirement already satisfied: statsmodels>=0.9.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from category-encoders==2.5.*->pytorch_tabular) (0.12.2)\n",
      "Requirement already satisfied: patsy>=0.5.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from category-encoders==2.5.*->pytorch_tabular) (0.5.2)\n",
      "Requirement already satisfied: scipy>=1.0.0 in /home/kwib/.local/lib/python3.9/site-packages (from category-encoders==2.5.*->pytorch_tabular) (1.10.1)\n",
      "Requirement already satisfied: tensorboardX>=2.2 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (2.6)\n",
      "Requirement already satisfied: tqdm>=4.57.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (4.62.3)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (4.4.0)\n",
      "Requirement already satisfied: packaging>=17.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (21.0)\n",
      "Requirement already satisfied: lightning-utilities!=0.4.0,>=0.3.0 in /home/kwib/.local/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (0.8.0)\n",
      "Requirement already satisfied: fsspec[http]>2021.06.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pytorch-lightning==1.8.*->pytorch_tabular) (2021.8.1)\n",
      "Requirement already satisfied: requests in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (2.26.0)\n",
      "Requirement already satisfied: aiohttp in /home/kwib/.local/lib/python3.9/site-packages (from fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (3.8.4)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>3.1->pytorch_tabular) (3.0.4)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>3.1->pytorch_tabular) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>3.1->pytorch_tabular) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>3.1->pytorch_tabular) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from matplotlib>3.1->pytorch_tabular) (8.4.0)\n",
      "Requirement already satisfied: six in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from cycler>=0.10->matplotlib>3.1->pytorch_tabular) (1.16.0)\n",
      "Requirement already satisfied: antlr4-python3-runtime==4.9.* in /home/kwib/.local/lib/python3.9/site-packages (from omegaconf>=2.0.1->pytorch_tabular) (4.9.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/kwib/.local/lib/python3.9/site-packages (from pandas>=1.1.5->pytorch_tabular) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pandas>=1.1.5->pytorch_tabular) (2021.3)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/kwib/.local/lib/python3.9/site-packages (from rich>=10.2.2->pytorch_tabular) (2.13.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/kwib/.local/lib/python3.9/site-packages (from rich>=10.2.2->pytorch_tabular) (2.2.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/kwib/.local/lib/python3.9/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.2.2->pytorch_tabular) (0.1.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from scikit-learn>=1.0.0->pytorch_tabular) (2.2.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/kwib/.local/lib/python3.9/site-packages (from scikit-learn>=1.0.0->pytorch_tabular) (1.2.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (58.0.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (2.0.2)\n",
      "Requirement already satisfied: wheel>=0.26 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (0.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (0.4.6)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (2.15.0)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (1.8.1)\n",
      "Requirement already satisfied: grpcio>=1.24.3 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (1.51.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in /home/kwib/.local/lib/python3.9/site-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (1.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /home/kwib/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (0.2.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /home/kwib/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (5.2.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /home/kwib/.local/lib/python3.9/site-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /home/kwib/.local/lib/python3.9/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (4.8.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (3.6.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /home/kwib/.local/lib/python3.9/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (0.4.8)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (3.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (2021.10.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from requests->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (1.26.7)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /home/kwib/.local/lib/python3.9/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_tabular) (3.2.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/kwib/.local/lib/python3.9/site-packages (from torch>=1.8.1->pytorch_tabular) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/kwib/.local/lib/python3.9/site-packages (from torch>=1.8.1->pytorch_tabular) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/kwib/.local/lib/python3.9/site-packages (from torch>=1.8.1->pytorch_tabular) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/kwib/.local/lib/python3.9/site-packages (from torch>=1.8.1->pytorch_tabular) (8.5.0.96)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/kwib/.local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (4.0.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (21.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/kwib/.local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/kwib/.local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/kwib/.local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (1.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/kwib/.local/lib/python3.9/site-packages (from aiohttp->fsspec[http]>2021.06.0->pytorch-lightning==1.8.*->pytorch_tabular) (1.9.2)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (3.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (5.1.0)\n",
      "Requirement already satisfied: ipython>=4.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (7.29.0)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (0.2.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (6.4.1)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (1.0.0)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipywidgets->pytorch_tabular) (5.7.0)\n",
      "Requirement already satisfied: debugpy<2.0,>=1.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (1.4.1)\n",
      "Requirement already satisfied: matplotlib-inline<0.2.0,>=0.1.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (0.1.2)\n",
      "Requirement already satisfied: tornado<7.0,>=4.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (6.1)\n",
      "Requirement already satisfied: jupyter-client<8.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (6.1.12)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (3.0.20)\n",
      "Requirement already satisfied: backcall in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.18.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.5)\n",
      "Requirement already satisfied: decorator in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from ipython>=4.0.0->ipywidgets->pytorch_tabular) (5.1.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.8.2)\n",
      "Requirement already satisfied: jupyter-core>=4.6.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (4.8.1)\n",
      "Requirement already satisfied: pyzmq>=13 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jupyter-client<8.0->ipykernel>=4.5.1->ipywidgets->pytorch_tabular) (22.2.1)\n",
      "Requirement already satisfied: fastjsonschema in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->pytorch_tabular) (2.16.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbformat>=4.2.0->ipywidgets->pytorch_tabular) (3.2.0)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jsonschema>=2.6->nbformat>=4.2.0->ipywidgets->pytorch_tabular) (0.18.0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->pytorch_tabular) (0.2.5)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (6.4.5)\n",
      "Requirement already satisfied: argon2-cffi in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (20.1.0)\n",
      "Requirement already satisfied: nbconvert in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (7.2.5)\n",
      "Requirement already satisfied: jinja2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (3.1.2)\n",
      "Requirement already satisfied: Send2Trash>=1.5.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.8.0)\n",
      "Requirement already satisfied: prometheus-client in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.11.0)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.9.4)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cffi>=1.0.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.14.6)\n",
      "Requirement already satisfied: pycparser in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from cffi>=1.0.0->argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (2.20)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (2.1.1)\n",
      "Requirement already satisfied: bleach in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (4.0.0)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.5.3)\n",
      "Requirement already satisfied: jupyterlab-pygments in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.1.2)\n",
      "Requirement already satisfied: tinycss2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.2.1)\n",
      "Requirement already satisfied: mistune<3,>=2.0.3 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (2.0.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (4.10.0)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.4.3)\n",
      "Requirement already satisfied: defusedxml in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.7.1)\n",
      "Requirement already satisfied: async-generator in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbclient>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.10)\n",
      "Requirement already satisfied: nest-asyncio in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from nbclient>=0.5.0->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (1.5.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (2.2.1)\n",
      "Requirement already satisfied: webencodings in /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3.9/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets->pytorch_tabular) (0.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytorch_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "90a4a26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:05:11.063986: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-24 03:05:11.190826: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-05-24 03:05:11.190860: I tensorflow/tsl/cuda/cudart_stub.cc:28] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-05-24 03:05:11.234078: E tensorflow/tsl/lib/monitoring/collection_registry.cc:81] Cannot register 2 metrics with the same name: /tensorflow/core/bfc_allocator_delay\n",
      "2023-05-24 03:05:12.224834: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libnvinfer.so.8'; dlerror: libnvinfer.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-05-24 03:05:12.224943: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libnvinfer_plugin.so.8'; dlerror: libnvinfer_plugin.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-05-24 03:05:12.224950: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/mixture_density/mdn.py:25: UserWarning: Wandb not installed. WandbLogger will not work.\n",
      "  warnings.warn(\"Wandb not installed. WandbLogger will not work.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "from keras_nlp.layers import PositionEmbedding\n",
    "\n",
    "import numpy.random as npr\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from generate_data import *\n",
    "from baseline_results import *\n",
    "from attention_model_adam import *\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import (\n",
    "    CategoryEmbeddingModelConfig, \n",
    "    FTTransformerConfig, \n",
    "    TabNetModelConfig, \n",
    "    GatedAdditiveTreeEnsembleConfig, \n",
    "    TabTransformerConfig, \n",
    "    AutoIntConfig\n",
    ")\n",
    "from pytorch_tabular.config import DataConfig, OptimizerConfig, TrainerConfig, ExperimentConfig\n",
    "from pytorch_tabular.models.common.heads import LinearHeadConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c589fd00",
   "metadata": {},
   "source": [
    "### Data processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9168068",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('auto-mpg.csv')\n",
    "data = data[data['horsepower'] != '?']\n",
    "data = data[(data['cylinders'] == 4) | (data['cylinders'] == 6) | (data['cylinders'] == 8)  ]\n",
    "data['horsepower'] = data['horsepower'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35847613",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.DataFrame()\n",
    "\n",
    "for i in data.columns:\n",
    "    if i in ['origin', 'car name']:\n",
    "        data2[i] = data[i]\n",
    "    elif i == 'cylinders':\n",
    "        data2[i] = np.array(data[i]/2 - 2).astype(int)\n",
    "    elif i == 'mpg':\n",
    "        data2['y'] = pd.qcut(data[i], 3, labels = False)\n",
    "    else:\n",
    "        data2[i] = pd.qcut(data[i], 3, labels = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53028e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data2[data2['origin'] == 1].reset_index(drop=True)\n",
    "test = data2[data2['origin'] != 1].reset_index(drop=True)\n",
    "\n",
    "del train['origin']\n",
    "del train['car name']\n",
    "del test['origin']\n",
    "del test['car name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "39db2eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['cylinders'] = pd.Categorical(test['cylinders'], categories=[0, 1, 2])\n",
    "test['displacement'] = pd.Categorical(test['displacement'], categories=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fbdf3252",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.columns = ['y'] + ['x'+str(i) for i in range(6)]\n",
    "test.columns = ['y'] + ['x'+str(i) for i in range(6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "998df5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[['x'+str(i) for i in range(6)] + ['y']]\n",
    "test = test[['x'+str(i) for i in range(6)] + ['y']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "25cf3d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test['x0'] = test['x0'].astype(int)\n",
    "test['x1'] = test['x1'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4ec9f5",
   "metadata": {},
   "source": [
    "### Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b13824f0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mse_train': [0.13877551020408163,\n",
       "  0.1469387755102041,\n",
       "  0.1346938775510204,\n",
       "  0.10204081632653061],\n",
       " 'acc_train': [0.8612244897959184,\n",
       "  0.8530612244897959,\n",
       "  0.8653061224489796,\n",
       "  0.8979591836734694],\n",
       " 'mse_test': [0.34285714285714286,\n",
       "  0.2785714285714286,\n",
       "  0.34285714285714286,\n",
       "  0.3],\n",
       " 'acc_test': [0.6571428571428571, 0.7214285714285714, 0.6571428571428571, 0.7]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_baseline_results(train = train, test = test, n_cat = 3, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8acb76a",
   "metadata": {},
   "source": [
    "### Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8adee13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:06:04.368031: W tensorflow/tsl/platform/default/dso_loader.cc:66] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/slurm/lib64:\n",
      "2023-05-24 03:06:04.368077: W tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:265] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2023-05-24 03:06:04.368097: I tensorflow/compiler/xla/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (gl3027.arc-ts.umich.edu): /proc/driver/nvidia/version does not exist\n",
      "2023-05-24 03:06:04.427825: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "14/14 - 4s - loss: 0.1777 - 4s/epoch - 262ms/step\n",
      "Epoch 2/200\n",
      "14/14 - 0s - loss: 0.1574 - 57ms/epoch - 4ms/step\n",
      "Epoch 3/200\n",
      "14/14 - 0s - loss: 0.1472 - 56ms/epoch - 4ms/step\n",
      "Epoch 4/200\n",
      "14/14 - 0s - loss: 0.1412 - 54ms/epoch - 4ms/step\n",
      "Epoch 5/200\n",
      "14/14 - 0s - loss: 0.1349 - 55ms/epoch - 4ms/step\n",
      "Epoch 6/200\n",
      "14/14 - 0s - loss: 0.1303 - 55ms/epoch - 4ms/step\n",
      "Epoch 7/200\n",
      "14/14 - 0s - loss: 0.1283 - 55ms/epoch - 4ms/step\n",
      "Epoch 8/200\n",
      "14/14 - 0s - loss: 0.1270 - 56ms/epoch - 4ms/step\n",
      "Epoch 9/200\n",
      "14/14 - 0s - loss: 0.1264 - 54ms/epoch - 4ms/step\n",
      "Epoch 10/200\n",
      "14/14 - 0s - loss: 0.1258 - 56ms/epoch - 4ms/step\n",
      "Epoch 11/200\n",
      "14/14 - 0s - loss: 0.1243 - 55ms/epoch - 4ms/step\n",
      "Epoch 12/200\n",
      "14/14 - 0s - loss: 0.1236 - 54ms/epoch - 4ms/step\n",
      "Epoch 13/200\n",
      "14/14 - 0s - loss: 0.1234 - 55ms/epoch - 4ms/step\n",
      "Epoch 14/200\n",
      "14/14 - 0s - loss: 0.1210 - 55ms/epoch - 4ms/step\n",
      "Epoch 15/200\n",
      "14/14 - 0s - loss: 0.1191 - 53ms/epoch - 4ms/step\n",
      "Epoch 16/200\n",
      "14/14 - 0s - loss: 0.1162 - 52ms/epoch - 4ms/step\n",
      "Epoch 17/200\n",
      "14/14 - 0s - loss: 0.1138 - 56ms/epoch - 4ms/step\n",
      "Epoch 18/200\n",
      "14/14 - 0s - loss: 0.1112 - 56ms/epoch - 4ms/step\n",
      "Epoch 19/200\n",
      "14/14 - 0s - loss: 0.1082 - 57ms/epoch - 4ms/step\n",
      "Epoch 20/200\n",
      "14/14 - 0s - loss: 0.1059 - 57ms/epoch - 4ms/step\n",
      "Epoch 21/200\n",
      "14/14 - 0s - loss: 0.1028 - 55ms/epoch - 4ms/step\n",
      "Epoch 22/200\n",
      "14/14 - 0s - loss: 0.1010 - 57ms/epoch - 4ms/step\n",
      "Epoch 23/200\n",
      "14/14 - 0s - loss: 0.0977 - 54ms/epoch - 4ms/step\n",
      "Epoch 24/200\n",
      "14/14 - 0s - loss: 0.0965 - 57ms/epoch - 4ms/step\n",
      "Epoch 25/200\n",
      "14/14 - 0s - loss: 0.0929 - 57ms/epoch - 4ms/step\n",
      "Epoch 26/200\n",
      "14/14 - 0s - loss: 0.0909 - 57ms/epoch - 4ms/step\n",
      "Epoch 27/200\n",
      "14/14 - 0s - loss: 0.0907 - 63ms/epoch - 4ms/step\n",
      "Epoch 28/200\n",
      "14/14 - 0s - loss: 0.0889 - 57ms/epoch - 4ms/step\n",
      "Epoch 29/200\n",
      "14/14 - 0s - loss: 0.0876 - 57ms/epoch - 4ms/step\n",
      "Epoch 30/200\n",
      "14/14 - 0s - loss: 0.0868 - 54ms/epoch - 4ms/step\n",
      "Epoch 31/200\n",
      "14/14 - 0s - loss: 0.0864 - 56ms/epoch - 4ms/step\n",
      "Epoch 32/200\n",
      "14/14 - 0s - loss: 0.0838 - 56ms/epoch - 4ms/step\n",
      "Epoch 33/200\n",
      "14/14 - 0s - loss: 0.0843 - 56ms/epoch - 4ms/step\n",
      "Epoch 34/200\n",
      "14/14 - 0s - loss: 0.0834 - 57ms/epoch - 4ms/step\n",
      "Epoch 35/200\n",
      "14/14 - 0s - loss: 0.0830 - 56ms/epoch - 4ms/step\n",
      "Epoch 36/200\n",
      "14/14 - 0s - loss: 0.0799 - 57ms/epoch - 4ms/step\n",
      "Epoch 37/200\n",
      "14/14 - 0s - loss: 0.0801 - 55ms/epoch - 4ms/step\n",
      "Epoch 38/200\n",
      "14/14 - 0s - loss: 0.0807 - 57ms/epoch - 4ms/step\n",
      "Epoch 39/200\n",
      "14/14 - 0s - loss: 0.0797 - 57ms/epoch - 4ms/step\n",
      "Epoch 40/200\n",
      "14/14 - 0s - loss: 0.0776 - 58ms/epoch - 4ms/step\n",
      "Epoch 41/200\n",
      "14/14 - 0s - loss: 0.0775 - 58ms/epoch - 4ms/step\n",
      "Epoch 42/200\n",
      "14/14 - 0s - loss: 0.0778 - 57ms/epoch - 4ms/step\n",
      "Epoch 43/200\n",
      "14/14 - 0s - loss: 0.0769 - 57ms/epoch - 4ms/step\n",
      "Epoch 44/200\n",
      "14/14 - 0s - loss: 0.0747 - 57ms/epoch - 4ms/step\n",
      "Epoch 45/200\n",
      "14/14 - 0s - loss: 0.0755 - 56ms/epoch - 4ms/step\n",
      "Epoch 46/200\n",
      "14/14 - 0s - loss: 0.0754 - 62ms/epoch - 4ms/step\n",
      "Epoch 47/200\n",
      "14/14 - 0s - loss: 0.0750 - 58ms/epoch - 4ms/step\n",
      "Epoch 48/200\n",
      "14/14 - 0s - loss: 0.0739 - 57ms/epoch - 4ms/step\n",
      "Epoch 49/200\n",
      "14/14 - 0s - loss: 0.0739 - 56ms/epoch - 4ms/step\n",
      "Epoch 50/200\n",
      "14/14 - 0s - loss: 0.0749 - 56ms/epoch - 4ms/step\n",
      "Epoch 51/200\n",
      "14/14 - 0s - loss: 0.0730 - 57ms/epoch - 4ms/step\n",
      "Epoch 52/200\n",
      "14/14 - 0s - loss: 0.0726 - 57ms/epoch - 4ms/step\n",
      "Epoch 53/200\n",
      "14/14 - 0s - loss: 0.0727 - 57ms/epoch - 4ms/step\n",
      "Epoch 54/200\n",
      "14/14 - 0s - loss: 0.0738 - 56ms/epoch - 4ms/step\n",
      "Epoch 55/200\n",
      "14/14 - 0s - loss: 0.0722 - 58ms/epoch - 4ms/step\n",
      "Epoch 56/200\n",
      "14/14 - 0s - loss: 0.0710 - 53ms/epoch - 4ms/step\n",
      "Epoch 57/200\n",
      "14/14 - 0s - loss: 0.0707 - 56ms/epoch - 4ms/step\n",
      "Epoch 58/200\n",
      "14/14 - 0s - loss: 0.0709 - 57ms/epoch - 4ms/step\n",
      "Epoch 59/200\n",
      "14/14 - 0s - loss: 0.0708 - 56ms/epoch - 4ms/step\n",
      "Epoch 60/200\n",
      "14/14 - 0s - loss: 0.0703 - 55ms/epoch - 4ms/step\n",
      "Epoch 61/200\n",
      "14/14 - 0s - loss: 0.0703 - 56ms/epoch - 4ms/step\n",
      "Epoch 62/200\n",
      "14/14 - 0s - loss: 0.0701 - 55ms/epoch - 4ms/step\n",
      "Epoch 63/200\n",
      "14/14 - 0s - loss: 0.0700 - 52ms/epoch - 4ms/step\n",
      "Epoch 64/200\n",
      "14/14 - 0s - loss: 0.0688 - 54ms/epoch - 4ms/step\n",
      "Epoch 65/200\n",
      "14/14 - 0s - loss: 0.0701 - 54ms/epoch - 4ms/step\n",
      "Epoch 66/200\n",
      "14/14 - 0s - loss: 0.0683 - 55ms/epoch - 4ms/step\n",
      "Epoch 67/200\n",
      "14/14 - 0s - loss: 0.0688 - 56ms/epoch - 4ms/step\n",
      "Epoch 68/200\n",
      "14/14 - 0s - loss: 0.0689 - 55ms/epoch - 4ms/step\n",
      "Epoch 69/200\n",
      "14/14 - 0s - loss: 0.0687 - 55ms/epoch - 4ms/step\n",
      "Epoch 70/200\n",
      "14/14 - 0s - loss: 0.0687 - 54ms/epoch - 4ms/step\n",
      "Epoch 71/200\n",
      "14/14 - 0s - loss: 0.0688 - 55ms/epoch - 4ms/step\n",
      "Epoch 72/200\n",
      "14/14 - 0s - loss: 0.0668 - 55ms/epoch - 4ms/step\n",
      "Epoch 73/200\n",
      "14/14 - 0s - loss: 0.0678 - 60ms/epoch - 4ms/step\n",
      "Epoch 74/200\n",
      "14/14 - 0s - loss: 0.0676 - 57ms/epoch - 4ms/step\n",
      "Epoch 75/200\n",
      "14/14 - 0s - loss: 0.0670 - 56ms/epoch - 4ms/step\n",
      "Epoch 76/200\n",
      "14/14 - 0s - loss: 0.0676 - 54ms/epoch - 4ms/step\n",
      "Epoch 77/200\n",
      "14/14 - 0s - loss: 0.0667 - 53ms/epoch - 4ms/step\n",
      "Epoch 78/200\n",
      "14/14 - 0s - loss: 0.0666 - 54ms/epoch - 4ms/step\n",
      "Epoch 79/200\n",
      "14/14 - 0s - loss: 0.0659 - 57ms/epoch - 4ms/step\n",
      "Epoch 80/200\n",
      "14/14 - 0s - loss: 0.0680 - 56ms/epoch - 4ms/step\n",
      "Epoch 81/200\n",
      "14/14 - 0s - loss: 0.0667 - 56ms/epoch - 4ms/step\n",
      "Epoch 82/200\n",
      "14/14 - 0s - loss: 0.0656 - 56ms/epoch - 4ms/step\n",
      "Epoch 83/200\n",
      "14/14 - 0s - loss: 0.0663 - 55ms/epoch - 4ms/step\n",
      "Epoch 84/200\n",
      "14/14 - 0s - loss: 0.0653 - 56ms/epoch - 4ms/step\n",
      "Epoch 85/200\n",
      "14/14 - 0s - loss: 0.0668 - 55ms/epoch - 4ms/step\n",
      "Epoch 86/200\n",
      "14/14 - 0s - loss: 0.0656 - 55ms/epoch - 4ms/step\n",
      "Epoch 87/200\n",
      "14/14 - 0s - loss: 0.0660 - 55ms/epoch - 4ms/step\n",
      "Epoch 88/200\n",
      "14/14 - 0s - loss: 0.0654 - 55ms/epoch - 4ms/step\n",
      "Epoch 89/200\n",
      "14/14 - 0s - loss: 0.0643 - 56ms/epoch - 4ms/step\n",
      "Epoch 90/200\n",
      "14/14 - 0s - loss: 0.0654 - 55ms/epoch - 4ms/step\n",
      "Epoch 91/200\n",
      "14/14 - 0s - loss: 0.0643 - 57ms/epoch - 4ms/step\n",
      "Epoch 92/200\n",
      "14/14 - 0s - loss: 0.0642 - 55ms/epoch - 4ms/step\n",
      "Epoch 93/200\n",
      "14/14 - 0s - loss: 0.0640 - 53ms/epoch - 4ms/step\n",
      "Epoch 94/200\n",
      "14/14 - 0s - loss: 0.0631 - 54ms/epoch - 4ms/step\n",
      "Epoch 95/200\n",
      "14/14 - 0s - loss: 0.0639 - 53ms/epoch - 4ms/step\n",
      "Epoch 96/200\n",
      "14/14 - 0s - loss: 0.0636 - 53ms/epoch - 4ms/step\n",
      "Epoch 97/200\n",
      "14/14 - 0s - loss: 0.0636 - 56ms/epoch - 4ms/step\n",
      "Epoch 98/200\n",
      "14/14 - 0s - loss: 0.0639 - 57ms/epoch - 4ms/step\n",
      "Epoch 99/200\n",
      "14/14 - 0s - loss: 0.0638 - 56ms/epoch - 4ms/step\n",
      "Epoch 100/200\n",
      "14/14 - 0s - loss: 0.0641 - 56ms/epoch - 4ms/step\n",
      "Epoch 101/200\n",
      "14/14 - 0s - loss: 0.0639 - 62ms/epoch - 4ms/step\n",
      "Epoch 102/200\n",
      "14/14 - 0s - loss: 0.0636 - 54ms/epoch - 4ms/step\n",
      "Epoch 103/200\n",
      "14/14 - 0s - loss: 0.0636 - 55ms/epoch - 4ms/step\n",
      "Epoch 104/200\n",
      "14/14 - 0s - loss: 0.0640 - 57ms/epoch - 4ms/step\n",
      "Epoch 105/200\n",
      "14/14 - 0s - loss: 0.0637 - 56ms/epoch - 4ms/step\n",
      "Epoch 106/200\n",
      "14/14 - 0s - loss: 0.0637 - 58ms/epoch - 4ms/step\n",
      "Epoch 107/200\n",
      "14/14 - 0s - loss: 0.0627 - 56ms/epoch - 4ms/step\n",
      "Epoch 108/200\n",
      "14/14 - 0s - loss: 0.0623 - 56ms/epoch - 4ms/step\n",
      "Epoch 109/200\n",
      "14/14 - 0s - loss: 0.0629 - 55ms/epoch - 4ms/step\n",
      "Epoch 110/200\n",
      "14/14 - 0s - loss: 0.0620 - 54ms/epoch - 4ms/step\n",
      "Epoch 111/200\n",
      "14/14 - 0s - loss: 0.0624 - 55ms/epoch - 4ms/step\n",
      "Epoch 112/200\n",
      "14/14 - 0s - loss: 0.0622 - 55ms/epoch - 4ms/step\n",
      "Epoch 113/200\n",
      "14/14 - 0s - loss: 0.0627 - 54ms/epoch - 4ms/step\n",
      "Epoch 114/200\n",
      "14/14 - 0s - loss: 0.0636 - 55ms/epoch - 4ms/step\n",
      "Epoch 115/200\n",
      "14/14 - 0s - loss: 0.0628 - 56ms/epoch - 4ms/step\n",
      "Epoch 116/200\n",
      "14/14 - 0s - loss: 0.0626 - 56ms/epoch - 4ms/step\n",
      "Epoch 117/200\n",
      "14/14 - 0s - loss: 0.0623 - 55ms/epoch - 4ms/step\n",
      "Epoch 118/200\n",
      "14/14 - 0s - loss: 0.0622 - 54ms/epoch - 4ms/step\n",
      "Epoch 119/200\n",
      "14/14 - 0s - loss: 0.0620 - 55ms/epoch - 4ms/step\n",
      "Epoch 120/200\n",
      "14/14 - 0s - loss: 0.0616 - 55ms/epoch - 4ms/step\n",
      "Epoch 121/200\n",
      "14/14 - 0s - loss: 0.0614 - 56ms/epoch - 4ms/step\n",
      "Epoch 122/200\n",
      "14/14 - 0s - loss: 0.0609 - 57ms/epoch - 4ms/step\n",
      "Epoch 123/200\n",
      "14/14 - 0s - loss: 0.0628 - 54ms/epoch - 4ms/step\n",
      "Epoch 124/200\n",
      "14/14 - 0s - loss: 0.0610 - 56ms/epoch - 4ms/step\n",
      "Epoch 125/200\n",
      "14/14 - 0s - loss: 0.0621 - 54ms/epoch - 4ms/step\n",
      "Epoch 126/200\n",
      "14/14 - 0s - loss: 0.0611 - 53ms/epoch - 4ms/step\n",
      "Epoch 127/200\n",
      "14/14 - 0s - loss: 0.0608 - 55ms/epoch - 4ms/step\n",
      "Epoch 128/200\n",
      "14/14 - 0s - loss: 0.0615 - 57ms/epoch - 4ms/step\n",
      "Epoch 129/200\n",
      "14/14 - 0s - loss: 0.0613 - 57ms/epoch - 4ms/step\n",
      "Epoch 130/200\n",
      "14/14 - 0s - loss: 0.0617 - 55ms/epoch - 4ms/step\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 131/200\n",
      "14/14 - 0s - loss: 0.0609 - 55ms/epoch - 4ms/step\n",
      "Epoch 132/200\n",
      "14/14 - 0s - loss: 0.0612 - 55ms/epoch - 4ms/step\n",
      "Epoch 133/200\n",
      "14/14 - 0s - loss: 0.0614 - 54ms/epoch - 4ms/step\n",
      "Epoch 134/200\n",
      "14/14 - 0s - loss: 0.0601 - 61ms/epoch - 4ms/step\n",
      "Epoch 135/200\n",
      "14/14 - 0s - loss: 0.0603 - 58ms/epoch - 4ms/step\n",
      "Epoch 136/200\n",
      "14/14 - 0s - loss: 0.0613 - 56ms/epoch - 4ms/step\n",
      "Epoch 137/200\n",
      "14/14 - 0s - loss: 0.0610 - 55ms/epoch - 4ms/step\n",
      "Epoch 138/200\n",
      "14/14 - 0s - loss: 0.0612 - 56ms/epoch - 4ms/step\n",
      "Epoch 139/200\n",
      "14/14 - 0s - loss: 0.0617 - 55ms/epoch - 4ms/step\n",
      "Epoch 140/200\n",
      "14/14 - 0s - loss: 0.0611 - 57ms/epoch - 4ms/step\n",
      "Epoch 141/200\n",
      "14/14 - 0s - loss: 0.0601 - 58ms/epoch - 4ms/step\n",
      "Epoch 142/200\n",
      "14/14 - 0s - loss: 0.0604 - 56ms/epoch - 4ms/step\n",
      "Epoch 143/200\n",
      "14/14 - 0s - loss: 0.0608 - 54ms/epoch - 4ms/step\n",
      "Epoch 144/200\n",
      "14/14 - 0s - loss: 0.0605 - 54ms/epoch - 4ms/step\n",
      "Epoch 145/200\n",
      "14/14 - 0s - loss: 0.0597 - 54ms/epoch - 4ms/step\n",
      "Epoch 146/200\n",
      "14/14 - 0s - loss: 0.0609 - 54ms/epoch - 4ms/step\n",
      "Epoch 147/200\n",
      "14/14 - 0s - loss: 0.0614 - 58ms/epoch - 4ms/step\n",
      "Epoch 148/200\n",
      "14/14 - 0s - loss: 0.0615 - 57ms/epoch - 4ms/step\n",
      "Epoch 149/200\n",
      "14/14 - 0s - loss: 0.0604 - 58ms/epoch - 4ms/step\n",
      "Epoch 150/200\n",
      "14/14 - 0s - loss: 0.0604 - 55ms/epoch - 4ms/step\n",
      "Epoch 151/200\n",
      "14/14 - 0s - loss: 0.0600 - 52ms/epoch - 4ms/step\n",
      "Epoch 152/200\n",
      "14/14 - 0s - loss: 0.0595 - 56ms/epoch - 4ms/step\n",
      "Epoch 153/200\n",
      "14/14 - 0s - loss: 0.0603 - 56ms/epoch - 4ms/step\n",
      "Epoch 154/200\n",
      "14/14 - 0s - loss: 0.0599 - 56ms/epoch - 4ms/step\n",
      "Epoch 155/200\n",
      "14/14 - 0s - loss: 0.0596 - 57ms/epoch - 4ms/step\n",
      "Epoch 156/200\n",
      "14/14 - 0s - loss: 0.0595 - 56ms/epoch - 4ms/step\n",
      "Epoch 157/200\n",
      "14/14 - 0s - loss: 0.0602 - 53ms/epoch - 4ms/step\n",
      "Epoch 158/200\n",
      "14/14 - 0s - loss: 0.0599 - 55ms/epoch - 4ms/step\n",
      "Epoch 159/200\n",
      "14/14 - 0s - loss: 0.0598 - 54ms/epoch - 4ms/step\n",
      "Epoch 160/200\n",
      "14/14 - 0s - loss: 0.0597 - 56ms/epoch - 4ms/step\n",
      "Epoch 161/200\n",
      "14/14 - 0s - loss: 0.0601 - 57ms/epoch - 4ms/step\n",
      "Epoch 162/200\n",
      "14/14 - 0s - loss: 0.0597 - 55ms/epoch - 4ms/step\n",
      "Epoch 163/200\n",
      "14/14 - 0s - loss: 0.0591 - 55ms/epoch - 4ms/step\n",
      "Epoch 164/200\n",
      "14/14 - 0s - loss: 0.0599 - 54ms/epoch - 4ms/step\n",
      "Epoch 165/200\n",
      "14/14 - 0s - loss: 0.0596 - 55ms/epoch - 4ms/step\n",
      "Epoch 166/200\n",
      "14/14 - 0s - loss: 0.0596 - 55ms/epoch - 4ms/step\n",
      "Epoch 167/200\n",
      "14/14 - 0s - loss: 0.0603 - 56ms/epoch - 4ms/step\n",
      "Epoch 168/200\n",
      "14/14 - 0s - loss: 0.0593 - 57ms/epoch - 4ms/step\n",
      "Epoch 169/200\n",
      "14/14 - 0s - loss: 0.0596 - 56ms/epoch - 4ms/step\n",
      "Epoch 170/200\n",
      "14/14 - 0s - loss: 0.0597 - 53ms/epoch - 4ms/step\n",
      "Epoch 171/200\n",
      "14/14 - 0s - loss: 0.0591 - 55ms/epoch - 4ms/step\n",
      "Epoch 172/200\n",
      "14/14 - 0s - loss: 0.0597 - 56ms/epoch - 4ms/step\n",
      "Epoch 173/200\n",
      "14/14 - 0s - loss: 0.0585 - 56ms/epoch - 4ms/step\n",
      "Epoch 174/200\n",
      "14/14 - 0s - loss: 0.0585 - 57ms/epoch - 4ms/step\n",
      "Epoch 175/200\n",
      "14/14 - 0s - loss: 0.0592 - 56ms/epoch - 4ms/step\n",
      "Epoch 176/200\n",
      "14/14 - 0s - loss: 0.0599 - 54ms/epoch - 4ms/step\n",
      "Epoch 177/200\n",
      "14/14 - 0s - loss: 0.0594 - 53ms/epoch - 4ms/step\n",
      "Epoch 178/200\n",
      "14/14 - 0s - loss: 0.0580 - 58ms/epoch - 4ms/step\n",
      "Epoch 179/200\n",
      "14/14 - 0s - loss: 0.0586 - 57ms/epoch - 4ms/step\n",
      "Epoch 180/200\n",
      "14/14 - 0s - loss: 0.0590 - 57ms/epoch - 4ms/step\n",
      "Epoch 181/200\n",
      "14/14 - 0s - loss: 0.0576 - 57ms/epoch - 4ms/step\n",
      "Epoch 182/200\n",
      "14/14 - 0s - loss: 0.0578 - 56ms/epoch - 4ms/step\n",
      "Epoch 183/200\n",
      "14/14 - 0s - loss: 0.0588 - 54ms/epoch - 4ms/step\n",
      "Epoch 184/200\n",
      "14/14 - 0s - loss: 0.0601 - 55ms/epoch - 4ms/step\n",
      "Epoch 185/200\n",
      "14/14 - 0s - loss: 0.0580 - 56ms/epoch - 4ms/step\n",
      "Epoch 186/200\n",
      "14/14 - 0s - loss: 0.0581 - 56ms/epoch - 4ms/step\n",
      "Epoch 187/200\n",
      "14/14 - 0s - loss: 0.0574 - 57ms/epoch - 4ms/step\n",
      "Epoch 188/200\n",
      "14/14 - 0s - loss: 0.0586 - 57ms/epoch - 4ms/step\n",
      "Epoch 189/200\n",
      "14/14 - 0s - loss: 0.0585 - 56ms/epoch - 4ms/step\n",
      "Epoch 190/200\n",
      "14/14 - 0s - loss: 0.0575 - 54ms/epoch - 4ms/step\n",
      "Epoch 191/200\n",
      "14/14 - 0s - loss: 0.0589 - 55ms/epoch - 4ms/step\n",
      "Epoch 192/200\n",
      "14/14 - 0s - loss: 0.0583 - 55ms/epoch - 4ms/step\n",
      "Epoch 193/200\n",
      "14/14 - 0s - loss: 0.0588 - 56ms/epoch - 4ms/step\n",
      "Epoch 194/200\n",
      "14/14 - 0s - loss: 0.0589 - 56ms/epoch - 4ms/step\n",
      "Epoch 195/200\n",
      "14/14 - 0s - loss: 0.0576 - 55ms/epoch - 4ms/step\n",
      "Epoch 196/200\n",
      "14/14 - 0s - loss: 0.0591 - 55ms/epoch - 4ms/step\n",
      "Epoch 197/200\n",
      "14/14 - 0s - loss: 0.0582 - 54ms/epoch - 4ms/step\n",
      "Epoch 198/200\n",
      "14/14 - 0s - loss: 0.0578 - 56ms/epoch - 4ms/step\n",
      "Epoch 199/200\n",
      "14/14 - 0s - loss: 0.0582 - 55ms/epoch - 4ms/step\n",
      "Epoch 200/200\n",
      "14/14 - 0s - loss: 0.0570 - 54ms/epoch - 4ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.14285714285714285,\n",
       " 0.8571428571428571,\n",
       " 0.20714285714285716,\n",
       " 0.7928571428571428)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_attention_model(train = train, test = test, n_cat = 3, embed_dim = 20, ff_dim = 5, num_head = 5, seed = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020cad48",
   "metadata": {},
   "source": [
    "### Other baselines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c5c1226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = DataConfig(\n",
    "    target=['y'], #target should always be a list. Multi-targets are only supported for regression. Multi-Task Classification is not implemented\n",
    "    continuous_cols=[],\n",
    "    categorical_cols=[x for x in train.columns if x != 'y'],\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(\n",
    "    batch_size=128,\n",
    "    max_epochs=200,\n",
    "    accelerator=\"auto\", # can be 'cpu','gpu', 'tpu', or 'ipu' \n",
    ")\n",
    "\n",
    "optimizer_config = OptimizerConfig()\n",
    "\n",
    "head_config = LinearHeadConfig(\n",
    "    layers=\"\", # No additional layer in head, just a mapping layer to output_dim\n",
    "    dropout=0.1,\n",
    "    initialization=\"kaiming\"\n",
    ").__dict__ # Convert to dict to pass to the model config (OmegaConf doesn't accept objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27390c4b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:07:13,706 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
      "[rank: 0] Global seed set to 42\n",
      "2023-05-24 03:07:13,750 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-05-24 03:07:13,751 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
      "2023-05-24 03:07:13,773 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: CategoryEmbeddingModel\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:132: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "2023-05-24 03:07:13,873 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-05-24 03:07:14,111 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> _backbone         CategoryEmbeddingBackbone   2.9 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> _embedding_layer  Embedding1dLayer               48 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> head              LinearHead                     99 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> loss              CrossEntropyLoss                0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m _backbone         CategoryEmbeddingBackbone   2.9 K \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m _embedding_layer  Embedding1dLayer               48 \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m head              LinearHead                     99 \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m loss              CrossEntropyLoss                0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 3.1 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 3.1 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 3.1 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 3.1 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f846e0ae3dc749369bebea985bf1d51d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:07:19,559 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-05-24 03:07:19,560 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a38196d940>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Category embedding\n",
    "\n",
    "model_config = CategoryEmbeddingModelConfig(\n",
    "    task=\"classification\",\n",
    "    layers=\"64-32\",  # Number of nodes in each layer\n",
    "    activation=\"ReLU\", # Activation between each layers\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "16c6b8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0de121425cd042a99522494cc4faf2e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7642857142857142\n",
      "0.2357142857142857\n"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "\n",
    "### Test accuracy\n",
    "print((pred_df['y'] == pred_df['prediction']).mean())\n",
    "\n",
    "### Test MSE\n",
    "print(((pred_df['y'] - pred_df['prediction'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "53f5eeb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/ft_transformer/config.py:229: UserWarning: Ignoring the deprecated arguments, `out_ff_layers`, `out_ff_activation`, `out_ff_dropoout`, and `out_ff_initialization` as head_config is passed.\n",
      "  warnings.warn(\n",
      "2023-05-24 03:19:23,384 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
      "[rank: 0] Global seed set to 42\n",
      "2023-05-24 03:19:23,408 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-05-24 03:19:23,409 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
      "2023-05-24 03:19:23,426 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: FTTransformerModel\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:132: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "2023-05-24 03:19:23,457 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-05-24 03:19:23,574 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /home/kwib/Attention embedding/UAI submission/Attention for tabular data/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                  </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> _backbone         FTTransformerBackbone   271 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> _embedding_layer  Embedding2dLayer        1.0 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> _head             LinearHead                 99 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> loss              CrossEntropyLoss            0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType                 \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m _backbone         FTTransformerBackbone   271 K \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m _embedding_layer  Embedding2dLayer        1.0 K \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m _head             LinearHead                 99 \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m loss              CrossEntropyLoss            0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 272 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 272 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 272 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 272 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c928217286447f682672b167c912ec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:19:27,934 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-05-24 03:19:27,934 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a38132b6a0>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### FTTransformer\n",
    "\n",
    "model_config = FTTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e5d1b53b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "576a9020de73467b8a40326df2c43450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071428571428572\n",
      "0.29285714285714287\n"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "\n",
    "### Test accuracy\n",
    "print((pred_df['y'] == pred_df['prediction']).mean())\n",
    "\n",
    "### Test MSE\n",
    "print(((pred_df['y'] - pred_df['prediction'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67000423",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/tab_transformer/config.py:219: UserWarning: Ignoring the deprecated arguments, `out_ff_layers`, `out_ff_activation`, `out_ff_dropoout`, and `out_ff_initialization` as head_config is passed.\n",
      "  warnings.warn(\n",
      "2023-05-24 03:20:02,755 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
      "[rank: 0] Global seed set to 42\n",
      "2023-05-24 03:20:02,774 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-05-24 03:20:02,774 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
      "2023-05-24 03:20:02,791 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: TabTransformerModel\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:132: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "2023-05-24 03:20:02,819 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-05-24 03:20:02,891 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /home/kwib/Attention embedding/UAI submission/Attention for tabular data/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> _backbone         TabTransformerBackbone   271 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> _embedding_layer  Embedding2dLayer           816 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> _head             LinearHead                 579 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> loss              CrossEntropyLoss             0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType                  \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m _backbone         TabTransformerBackbone   271 K \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m _embedding_layer  Embedding2dLayer           816 \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m _head             LinearHead                 579 \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m loss              CrossEntropyLoss             0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 272 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 272 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 1                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 272 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 272 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 1                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0692f97680bb46c1a1ea05fd13ced408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:20:05,752 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-05-24 03:20:05,753 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a380fa08e0>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TabTransformer\n",
    "\n",
    "model_config = TabTransformerConfig(\n",
    "    task=\"classification\",\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1506b8c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a13d69587b704370a52f0d000f03dd0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7071428571428572\n",
      "0.29285714285714287\n"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "\n",
    "### Test accuracy\n",
    "print((pred_df['y'] == pred_df['prediction']).mean())\n",
    "\n",
    "### Test MSE\n",
    "print(((pred_df['y'] - pred_df['prediction'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b046df1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:20:38,395 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
      "[rank: 0] Global seed set to 42\n",
      "2023-05-24 03:20:38,418 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-05-24 03:20:38,419 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
      "2023-05-24 03:20:38,436 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: AutoIntModel\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:132: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "2023-05-24 03:20:38,460 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-05-24 03:20:38,572 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /home/kwib/Attention embedding/UAI submission/Attention for tabular data/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> _backbone         AutoIntBackbone   13.8 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> _embedding_layer  Embedding2dLayer     504 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> _head             LinearHead           579 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> loss              CrossEntropyLoss       0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m _backbone         AutoIntBackbone   13.8 K \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m _embedding_layer  Embedding2dLayer     504 \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m _head             LinearHead           579 \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m loss              CrossEntropyLoss       0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 14.8 K                                                                                           \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 14.8 K                                                                                               \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 14.8 K                                                                                           \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 14.8 K                                                                                               \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718a772172164e01b06a2c061e53ddd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:20:41,479 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-05-24 03:20:41,479 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a380d1c760>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### AutoInt\n",
    "\n",
    "model_config = AutoIntConfig(\n",
    "    task=\"classification\",\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65ee9911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea85eeb6f6b4534ae7712b3f0832989",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.36428571428571427\n",
      "0.6357142857142857\n"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "\n",
    "### Test accuracy\n",
    "print((pred_df['y'] == pred_df['prediction']).mean())\n",
    "\n",
    "### Test MSE\n",
    "print(((pred_df['y'] - pred_df['prediction'])**2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0488ce49",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:21:29,291 - {pytorch_tabular.tabular_model:102} - INFO - Experiment Tracking is turned off\n",
      "[rank: 0] Global seed set to 42\n",
      "2023-05-24 03:21:29,311 - {pytorch_tabular.tabular_model:465} - INFO - Preparing the DataLoaders\n",
      "2023-05-24 03:21:29,311 - {pytorch_tabular.tabular_datamodule:286} - INFO - Setting up the datamodule for classification task\n",
      "2023-05-24 03:21:29,329 - {pytorch_tabular.tabular_model:508} - INFO - Preparing the Model: TabNetModel\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:126: UserWarning: Wandb is not installed. Please install wandb to log logits. You can install wandb using pip install wandb or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_tabular/models/base_model.py:132: UserWarning: Plotly is not installed. Please install plotly to log logits. You can install plotly using pip install plotly or install PyTorch Tabular using pip install pytorch-tabular[all]\n",
      "  warnings.warn(\n",
      "2023-05-24 03:21:29,375 - {pytorch_tabular.tabular_model:264} - INFO - Preparing the Trainer\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "2023-05-24 03:21:29,447 - {pytorch_tabular.tabular_model:566} - INFO - Training Started\n",
      "/home/kwib/.local/lib/python3.9/site-packages/lightning_lite/plugins/environments/slurm.py:167: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /sw/pkgs/arc/python3.9-anaconda/2021.11/lib/python3. ...\n",
      "  rank_zero_warn(\n",
      "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:604: UserWarning: Checkpoint directory /home/kwib/Attention embedding/UAI submission/Attention for tabular data/saved_models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type             </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>\n",
       "\n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span> _embedding_layer  Identity               0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span> _backbone         TabNetBackbone     6.5 K \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span> _head             Identity               0 \n",
       "<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span> loss              CrossEntropyLoss       0 \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mType            \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m\n",
       "\n",
       "\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m _embedding_layer  Identity               0 \n",
       "\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m _backbone         TabNetBackbone     6.5 K \n",
       "\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m _head             Identity               0 \n",
       "\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m loss              CrossEntropyLoss       0 \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 6.5 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 6.5 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 6.5 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 6.5 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828705466c154766b2f02d0073f3f220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/home/kwib/.local/lib/python3.9/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:224: \n",
       "PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. \n",
       "Consider increasing the value of the `num_workers` argument` (try 36 which is the number of cpus on this machine) \n",
       "in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-24 03:21:32,272 - {pytorch_tabular.tabular_model:568} - INFO - Training the model completed\n",
      "2023-05-24 03:21:32,273 - {pytorch_tabular.tabular_model:1207} - INFO - Loading the best model\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x14a380cbab80>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### TabNet\n",
    "\n",
    "model_config = TabNetModelConfig(\n",
    "    task=\"classification\",\n",
    "    learning_rate = 1e-3,\n",
    "    head = \"LinearHead\", #Linear Head\n",
    "    head_config = head_config, # Linear Head Config\n",
    ")\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c26fe41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e425631f6173425daf4857ff4bed2b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6\n",
      "0.4857142857142857\n"
     ]
    }
   ],
   "source": [
    "pred_df = tabular_model.predict(test)\n",
    "\n",
    "### Test accuracy\n",
    "print((pred_df['y'] == pred_df['prediction']).mean())\n",
    "\n",
    "### Test MSE\n",
    "print(((pred_df['y'] - pred_df['prediction'])**2).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
